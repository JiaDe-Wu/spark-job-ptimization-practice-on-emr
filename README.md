# spark-demo

实践一次Spark作业的调优，最终将4.5小时的任务优化为1.1小时完成，过程中测试不同参数和配置下的作业运行效果，深入的解读EMR中运行Spark多项重要配置参数意义，这些参数将影响包括性能优化，资源分配，成本降低，编码/配置作业中的常见错误等。

实践中，我们将以150G的TXT格式公开数据集作为测试对象，使用Amazon EC2下载并将数据导入到Amazon S3，使用Amazon EMR集群运行Apache Spark进行数据处理，我们也将在该环节进行多种配置参数的调测并重点展开。
首先，我们使用一台Amazon EC2从FreddieMac下载测试数据，FreddieMac提供了美国单亲家庭购房贷款的近20年的历史数据，可免费用于非商业的学术/研究性工作，原始数据包含50多个属性近250亿条数据，经过我们处理的数据还可以进行机器学习等其他尝试。我准备了简单的Python遍历脚本去自动下载并解压数据集，这里我们使用1999年至2019年20年的数据测试，代码如下，在main方法中需要我们在FreddieMac注册并在代码中填入您的账号，也可以在这里依据需要测试的数据大小定义历史数据起始年份。
...............
原文地址：https://aws.amazon.com/cn/blogs/china/spark-job-ptimization-practice-on-emr/

